{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95d6291f-36a8-415c-9f1c-45a2f8f83e14",
   "metadata": {},
   "source": [
    "# 1. Install Dependencies and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c10037f-f958-4a1e-9823-2a8e1e3fa2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.10.0 tensorflow_gpu==2.10.0 opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c50016d-aae7-4e48-a7d3-7cf41b249ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637dc179-82d3-46af-906c-1db2f000413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ce8c2-7bae-4fff-b607-45607a19d3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10ce176-2546-406b-b968-c3101262e6a8",
   "metadata": {},
   "source": [
    "# 2. Load Data\n",
    "\n",
    "## 2.1 Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1551ec38-1d49-4005-8d5b-828d8fdd52d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(x): \n",
    "    byte_img = tf.io.read_file(x)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72947661-4e87-4099-9c4d-9ccee351c870",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = tf.data.Dataset.list_files('aug_data\\\\train\\\\images\\\\*.jpg', shuffle=False)\n",
    "train_images = train_images.map(load_image)\n",
    "train_images = train_images.map(lambda x: tf.image.resize(x, (250,250)))\n",
    "train_images = train_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df889d4d-3fd4-41fb-93ea-1e884f49af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_images.as_numpy_iterator().next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdff50f-4670-4038-a3eb-ba68b35a31bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = tf.data.Dataset.list_files('aug_data\\\\test\\\\images\\\\*.jpg', shuffle=False)\n",
    "test_images = test_images.map(load_image)\n",
    "test_images = test_images.map(lambda x: tf.image.resize(x, (250,250)))\n",
    "test_images = test_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a83da66-67ac-4df7-906c-f57d1063ef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = tf.data.Dataset.list_files('aug_data\\\\val\\\\images\\\\*.jpg', shuffle=False)\n",
    "val_images = val_images.map(load_image)\n",
    "val_images = val_images.map(lambda x: tf.image.resize(x, (250,250)))\n",
    "val_images = val_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb8f1ab-f0b5-4bbb-b2ee-b9b22e9f23b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(val_images.as_numpy_iterator().next())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ec64f7-8425-4df7-8cf9-2f44c508b0ab",
   "metadata": {},
   "source": [
    "## 2.2 Prepare Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503ef24c-8526-4551-b104-18829c008148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_path):\n",
    "    with open(label_path.numpy(), 'r', encoding = \"utf-8\") as f:\n",
    "        label = json.load(f)\n",
    "        \n",
    "    return [label['keypoints']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997bff3b-6891-4fdf-a383-8afd256ae2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.data.Dataset.list_files('aug_data\\\\train\\\\labels\\\\*.json', shuffle=False)\n",
    "train_labels = train_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5399468c-71b3-4aa7-abd7-b6d620bb7a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = tf.data.Dataset.list_files('aug_data\\\\test\\\\labels\\\\*.json', shuffle=False)\n",
    "test_labels = test_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f23ed2-8afd-4aa2-be33-897199ccc395",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = tf.data.Dataset.list_files('aug_data\\\\val\\\\labels\\\\*.json', shuffle=False)\n",
    "val_labels = val_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8329bc0a-6d0c-489c-b9b0-735efcfbacfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c83672-de27-4d66-8342-42bad8969133",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_images), len(train_labels), len(test_images), len(test_labels), len(val_images), len(val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a926ee67-0095-4b3a-a617-b96b61e8b9ed",
   "metadata": {},
   "source": [
    "## 2.3. Combine Labels and Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9b346e-0896-457c-975e-d6661c5096bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.zip((train_images, train_labels))\n",
    "train = train.shuffle(7000)\n",
    "train = train.batch(16)\n",
    "train = train.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2c9238-85e1-41f8-be25-f17ce7df390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.data.Dataset.zip((test_images, test_labels))\n",
    "test = test.shuffle(1500)\n",
    "test = test.batch(16)\n",
    "test = test.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbdf15a-6209-44fa-86c6-e403b00b0ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = tf.data.Dataset.zip((val_images, val_labels))\n",
    "val = val.shuffle(1500)\n",
    "val = val.batch(16)\n",
    "val = val.prefetch(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcc67d3-a555-4e7a-91e4-29ba17bf6060",
   "metadata": {},
   "source": [
    "## 2.4 View Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d82c08-e30e-4a04-828b-e43da90db2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_samples = train.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0845bdef-975c-45fa-9d75-6faec8c33d54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = data_samples.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b759bf42-e881-44c3-a1cd-9827a537c5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61256c29-5a58-4b1c-83f6-fbfa995ae728",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx in range(4): \n",
    "    sample_image = res[0][idx]\n",
    "    sample_coords = res[1][0][idx]\n",
    "    \n",
    "    # Red circle - Left\n",
    "    cv2.circle(sample_image, tuple(np.multiply(sample_coords[:2], [250,250]).astype(int)), 5, (255,0,0), -1)\n",
    "    # Green circle - Right\n",
    "    cv2.circle(sample_image, tuple(np.multiply(sample_coords[2:], [250,250]).astype(int)), 5, (0,255,0), -1)\n",
    "\n",
    "    ax[idx].imshow(sample_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45564a67-bdf8-4188-a9b8-b3efa7c914a8",
   "metadata": {},
   "source": [
    "# 3. Build Model\n",
    "\n",
    "## 3.1 Create Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26f902c-6b28-4d17-a24e-fc488bb1d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, Reshape, Dropout\n",
    "from tensorflow.keras.applications import ResNet152V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb625715-89e6-41c1-aaee-84b67e0d2e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(250,250,3)), \n",
    "    ResNet152V2(include_top=False, input_shape=(250,250,3)),\n",
    "    Conv2D(512, 3, padding='same', activation='relu'),\n",
    "    Conv2D(512, 3, padding='same', activation='relu'),\n",
    "    Conv2D(256, 3, 2, padding='same', activation='relu'),\n",
    "    Conv2D(256, 2, 2, activation='relu'),\n",
    "    Dropout(0.05),\n",
    "    Conv2D(4, 2, 2),\n",
    "    Reshape((4,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8957a11-3def-445e-ac4c-64e5cb4f0810",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978b7db8-b79d-4ee5-ba49-c703c6770fb9",
   "metadata": {},
   "source": [
    "## 3.2 Setup Losses and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1cc290-2743-43a6-b839-8b6e209c475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, decay=0.0007)\n",
    "loss = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5105eaf-0b90-4196-a2d3-446df525890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe96d75c-f82b-44ee-a9c4-d3920e3222a7",
   "metadata": {},
   "source": [
    "## 3.3 Sense Check predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9619934-dac5-499c-8456-760832dc2663",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04468020-2663-40af-a920-15c11547329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181e9b3e-d612-43f3-bade-5ac15eaf53bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca446cc-b672-42f2-88e6-97b21a8fa0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99b6449-f201-42ac-8d25-29bbdeb458ac",
   "metadata": {},
   "source": [
    "## 3.4 Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88c84d9-6f93-4ece-bcba-a043c11732b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for 100 epochs\n",
    "hist = model.fit(train, epochs=100, validation_data=val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe87f03-a8e7-4710-a4cd-f2215098c262",
   "metadata": {},
   "source": [
    "# 4. Review Performance\n",
    "\n",
    "## 4.1 View Loss Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12d8cb2-433b-4405-9520-250f09685991",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded4b080-fead-4e19-8359-c4e06d8bf70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val loss')\n",
    "plt.suptitle('Loss Plot - Training vs Val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46369d51-af34-478b-afa4-98312893e273",
   "metadata": {},
   "source": [
    "## 4.2. Make Predictions on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8191e4-6c40-4edc-bed6-db6d32dc174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fb160e-bb8c-4257-b362-93164d847202",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = test_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d377f6e7-2a05-4165-b271-dcc43f655ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(test_sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c8b2b6-84d7-477f-b074-e7b9b2c76d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx in range(4): \n",
    "    sample_image = test_sample[0][idx]\n",
    "    sample_coords = yhat[idx]\n",
    "    \n",
    "    # Red circle - Left\n",
    "    cv2.circle(sample_image, tuple(np.multiply(sample_coords[:2], [250,250]).astype(int)), 2, (255,0,0), -1)\n",
    "    # Green circle - Right\n",
    "    cv2.circle(sample_image, tuple(np.multiply(sample_coords[2:], [250,250]).astype(int)), 2, (0,255,0), -1)\n",
    "    \n",
    "    ax[idx].imshow(sample_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b821034c-0039-41fc-a0d5-7f4060224e73",
   "metadata": {},
   "source": [
    "## 4.3. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ecc947-5027-4080-aded-0eae8830e67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e087a28b-282a-4613-92b5-4b60da959e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('eyetracker100epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d1ee59-5a03-4e6c-a546-bbe6b96a81d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('eyetracker100epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc5c65d-c681-4ecd-ae08-0d5961e6abf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(test_sample[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb0c692-5b28-4469-9026-9d47596ebb88",
   "metadata": {},
   "source": [
    "# 5. Real Time Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6206e3-3b00-4feb-a755-a5d0ca0598fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    _ , frame = cap.read()\n",
    "    \n",
    "    frame = frame[50:500,50:500,:] \n",
    "    rgb_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    resized = cv2.resize(rgb_img, (250,250))\n",
    "    \n",
    "    yhat = model.predict(np.expand_dims(resized/255,0))\n",
    "    sample_coords = yhat[0,:4]\n",
    "    \n",
    "    cv2.circle(frame, tuple(np.multiply(sample_coords[:2], [450,450]).astype(int)), 2, (255,0,0), -1)\n",
    "    cv2.circle(frame, tuple(np.multiply(sample_coords[2:], [450,450]).astype(int)), 2, (0,255,0), -1)\n",
    "    \n",
    "    cv2.imshow('EyeTrack', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
