{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ba67908-c413-4721-9bf8-1bd326a31c69",
   "metadata": {},
   "source": [
    "# 1. Install Dependencies and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf455e3c-7d19-48f2-aed8-e3307b5ef1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install labelme tensorflow==2.10.0 tensorflow_gpu==2.10.0 opencv-python matplotlib albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134244f9-8035-4dff-bc7e-701f41b3237a",
   "metadata": {},
   "source": [
    "# 2. Collect Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0bb956-6044-47b1-9b13-2faf60cc2487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c50016d-aae7-4e48-a7d3-7cf41b249ebc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5827018c-bbfd-48c5-bd52-4aba449fc2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = os.path.join('data','images')\n",
    "number_images = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2af139-a351-4a7c-94ca-8121a8b1ba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "for imgnum in range(number_images):\n",
    "    print('Collecting image {}'.format(imgnum))\n",
    "    ret, frame = cap.read()\n",
    "    imgname = os.path.join(IMAGES_PATH,f'{str(uuid.uuid1())}.jpg')\n",
    "    cv2.imwrite(imgname, frame)\n",
    "    cv2.imshow('frame', frame)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9284902f-88a3-4647-9fa4-12c25020a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "!labelme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f73062c-5965-49eb-b171-3ec1f9a40427",
   "metadata": {},
   "source": [
    "# 3. Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72076f6d-f950-4a26-86fc-60fcdb7c4576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d09faa8-83f2-4648-9f30-0a7351281cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2efcf2-ba1c-4a38-9d6f-508bade421dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c4bfa6-23b0-432c-90b2-04b3f3ea8900",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = tf.data.Dataset.list_files('data\\\\images\\\\*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1551ec38-1d49-4005-8d5b-828d8fdd52d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(x): \n",
    "    byte_img = tf.io.read_file(x)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e67dd21-8bb9-4f4d-bcd0-e53289cf12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.map(load_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b066c7-b3b5-4f96-8151-f779f68bc66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3097cf-75f7-4276-8a69-564b74018523",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = images.batch(4).as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e21f28c-c18a-4870-8f53-47005563cdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images = image_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88a3a42-ec5b-4151-acf4-6286d1e3cc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx, image in enumerate(plot_images):\n",
    "    ax[idx].imshow(image) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed332b4b-bd1f-4f6f-bd6a-7f63e95f2ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "80*.7 # 56 to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcca56a3-147c-470c-823d-da1ac3460383",
   "metadata": {},
   "outputs": [],
   "source": [
    "80*.15 # 12 for each test and val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de013810-bb73-415e-9caf-71c2ce662da2",
   "metadata": {},
   "source": [
    "# 4. Move Matching Labels AFTER Annotation with Labelme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db41512a-f67d-4888-8e3a-2b5d106ada24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in ['train','test','val']:\n",
    "    for file in os.listdir(os.path.join('data', folder, 'images')):\n",
    "        \n",
    "        filename = file.split('.')[0]+'.json'\n",
    "        existing_filepath = os.path.join('data','labels', filename)\n",
    "        if os.path.exists(existing_filepath): \n",
    "            new_filepath = os.path.join('data',folder,'labels',filename)\n",
    "            os.replace(existing_filepath, new_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c74d28c-a2e3-4fc6-a4d6-55656ce9d5d5",
   "metadata": {},
   "source": [
    "# 5. Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf95f00-e757-43f8-9bc4-eb783038e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as alb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f330fda6-930e-4c8e-a851-7b5a69681f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = alb.Compose([alb.RandomCrop(width=450, height=450), \n",
    "                         alb.HorizontalFlip(p=0.5), \n",
    "                         alb.RandomBrightnessContrast(p=0.2),\n",
    "                         alb.RandomGamma(p=0.2), \n",
    "                         alb.RGBShift(p=0.2), \n",
    "                         alb.VerticalFlip(p=0.5)], \n",
    "                        keypoint_params=alb.KeypointParams(format='xy', label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218597b0-09db-4828-bc19-c5cd8e291ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join('data','train', 'images','cf624540-f45c-11ed-98ca-c01803b4686d.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf0563d-1e32-40f8-99cc-e0a1807a036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('data', 'train', 'labels', 'cf624540-f45c-11ed-98ca-c01803b4686d.json'), 'r') as f:\n",
    "    label = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930cc0ac-86d8-49fa-857d-d8c8ffc7f602",
   "metadata": {},
   "outputs": [],
   "source": [
    "label['shapes'][0]['points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a8f31b-53fa-4ebd-930d-cb9980fa9129",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = [0,0,0,0]\n",
    "coords[0] = label['shapes'][0]['points'][0][0]\n",
    "coords[1] = label['shapes'][0]['points'][0][1]\n",
    "coords[2] = label['shapes'][1]['points'][0][0]\n",
    "coords[3] = label['shapes'][1]['points'][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae92de9-b4e2-4c61-9b2d-b0edfa567500",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6023c6c4-3e7f-4edf-a7be-3b47661fed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = list(np.divide(coords, [640,480,640,480]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f717ec0b-c0b7-498a-a4e3-4c0fa1c960c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b73651c-7339-4a27-83a1-d8a7038f6600",
   "metadata": {},
   "outputs": [],
   "source": [
    "for partition in ['train', 'test', 'val']: \n",
    "    for image in os.listdir(os.path.join('data', partition, 'images')):\n",
    "        img = cv2.imread(os.path.join('data', partition, 'images', image))\n",
    "\n",
    "        classes = [0,0]\n",
    "        coords = [0,0,0.00001,0.00001]\n",
    "        label_path = os.path.join('data', partition, 'labels', f'{image.split(\".\")[0]}.json')\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                label = json.load(f)\n",
    "    \n",
    "            if label['shapes'][0]['label']=='LeftEye': \n",
    "                classes[0] = 1\n",
    "                coords[0] = np.squeeze(label['shapes'][0]['points'])[0]\n",
    "                coords[1] = np.squeeze(label['shapes'][0]['points'])[1]\n",
    "\n",
    "            if label['shapes'][0]['label']=='RightEye':\n",
    "                classes[1] = 1\n",
    "                coords[2] = np.squeeze(label['shapes'][0]['points'])[0]\n",
    "                coords[3] = np.squeeze(label['shapes'][0]['points'])[1]\n",
    "\n",
    "            if len(label['shapes']) > 1:     \n",
    "                if label['shapes'][1]['label'] =='LeftEye': \n",
    "                    classes[0] = 1 \n",
    "                    coords[0] = np.squeeze(label['shapes'][1]['points'])[0]\n",
    "                    coords[1] = np.squeeze(label['shapes'][1]['points'])[1]\n",
    "\n",
    "                if label['shapes'][1]['label'] =='RightEye': \n",
    "                    classes[1] = 1\n",
    "                    coords[2] = np.squeeze(label['shapes'][1]['points'])[0]\n",
    "                    coords[3] = np.squeeze(label['shapes'][1]['points'])[1]\n",
    "            \n",
    "            np.divide(coords, [640,480,640,480])\n",
    "                \n",
    "        try: \n",
    "            for x in range(120):\n",
    "                keypoints = [(coords[:2]), (coords[2:])]\n",
    "                augmented = augmentor(image=img, keypoints=keypoints, class_labels=['LeftEye','RightEye'])\n",
    "                cv2.imwrite(os.path.join('aug_data', partition, 'images', f'{image.split(\".\")[0]}.{x}.jpg'), augmented['image'])\n",
    "\n",
    "                annotation = {}\n",
    "                annotation['image'] = image\n",
    "                annotation['class'] = [0,0]\n",
    "                annotation['keypoints'] = [0,0,0,0]\n",
    "\n",
    "                if os.path.exists(label_path):\n",
    "                    if len(augmented['keypoints']) > 0: \n",
    "                        for idx, cl in enumerate(augmented['class_labels']):\n",
    "                            if cl == 'LeftEye': \n",
    "                                annotation['class'][0] = 1 \n",
    "                                annotation['keypoints'][0] = augmented['keypoints'][idx][0]\n",
    "                                annotation['keypoints'][1] = augmented['keypoints'][idx][1]\n",
    "                            if cl == 'RightEye': \n",
    "                                annotation['class'][1] = 1 \n",
    "                                annotation['keypoints'][2] = augmented['keypoints'][idx][0]\n",
    "                                annotation['keypoints'][3] = augmented['keypoints'][idx][1]\n",
    "                                \n",
    "                annotation['keypoints'] = list(np.divide(annotation['keypoints'], [450,450,450,450]))\n",
    "\n",
    "\n",
    "                with open(os.path.join('aug_data', partition, 'labels', f'{image.split(\".\")[0]}.{x}.json'), 'w') as f:\n",
    "                    json.dump(annotation, f)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-autonumbering": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
